{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "import pytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el dataset desde un archivo CSV\n",
    "dataset = pd.read_csv(r\"../../data/processed/TCGA_GBM_LGG_Mutations_clean_v2.csv\") # cambiar la ruta al probar\n",
    "\n",
    "# Crear un DataFrame a partir del dataset leído\n",
    "dataset_df = pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "# Convertir la columna \"Grade\" a tipo categórico\n",
    "dataset_df[\"Grade\"] = dataset_df[\"Grade\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePipeline:\n",
    "    def __init__(self):\n",
    "        self.frame = None\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        self.model = None\n",
    "        self.load_dataset()\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Carga el dataset y realiza la división en conjuntos de entrenamiento y prueba.\"\"\"\n",
    "        dataset = pd.read_csv(r\"../../data/processed/TCGA_GBM_LGG_Mutations_clean_v2.csv\") # cambiar la ruta al probar\n",
    "        self.frame = pd.DataFrame(dataset, columns=dataset.columns)\n",
    "        self.frame[\"Grade\"] = self.frame[\"Grade\"].astype('category')  # Convertir la columna \"Grade\" a tipo categórico\n",
    "        \n",
    "        # Obtener los nombres de las características excluyendo la columna 'Grade'\n",
    "        feature_names = [col for col in self.frame.columns if col != 'Grade']\n",
    "        \n",
    "        # Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.frame[feature_names], self.frame['Grade'], test_size=0.65, random_state=42)\n",
    "        \n",
    "    def train(self, algorithm=LogisticRegression):\n",
    "        \"\"\"Entrenar el modelo usando el algoritmo especificado (por defecto LogisticRegression).\"\"\"\n",
    "        self.model = algorithm(solver='lbfgs', multi_class='auto')\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        \"\"\"Realizar predicciones usando el modelo entrenado.\"\"\"\n",
    "        return self.model.predict(input_data)\n",
    "        \n",
    "    def get_accuracy(self):\n",
    "        \"\"\"Obtener la precisión del modelo en el conjunto de prueba.\"\"\"\n",
    "        return self.model.score(X=self.X_test, y=self.y_test)\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Método de ejecución para correr el pipeline varias veces.\"\"\"\n",
    "        self.load_dataset()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo es: 0.9157706093189965\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia de la clase SimplePipeline\n",
    "pipeline = SimplePipeline()\n",
    "\n",
    "# Ejecutar el pipeline, lo que incluye cargar el dataset, entrenar el modelo, etc.\n",
    "pipeline.run_pipeline()\n",
    "\n",
    "# Obtener la precisión del modelo en el conjunto de prueba\n",
    "accuracy_score = pipeline.get_accuracy()\n",
    "\n",
    "# Imprimir la precisión del modelo\n",
    "print(f'La precisión del modelo es: {accuracy_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo el esquema\n",
    "tumor_schema = {\n",
    "    'Grade': {\n",
    "        'allowed_values': [0, 1],  # Ajusta según los valores de grado observados\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'Gender': {\n",
    "        'allowed_values': [0, 1],  # 0 para femenino, 1 para masculino (si aplica)\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'Age_at_diagnosis': {\n",
    "        'range': {\n",
    "            'min': 0,\n",
    "            'max': 120  # Rango típico de edad en años\n",
    "        },\n",
    "        'dtype': float,  # Tipo de dato: flotante\n",
    "    },\n",
    "    'Race': {\n",
    "        'allowed_values': [0, 1, 2, 3],  # Ajusta según las categorías de raza en el dataset\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'Tumor_Specification': {\n",
    "        'allowed_values': [0, 1, 2],  # Ajusta según las especificaciones tumorales observadas\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    # Genes mutados (0: No mutado, 1: Mutado)\n",
    "    'PTEN': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'EGFR': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'CIC': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'MUC16': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'PIK3CA': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'NF1': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'PIK3R1': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'FUBP1': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'RB1': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'NOTCH1': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'BCOR': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'CSMD3': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'SMARCA4': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'GRIN2A': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'IDH2': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'FAT4': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    },\n",
    "    'PDGFRA': {\n",
    "        'allowed_values': [0, 1],  # Valores permitidos: 0 o 1\n",
    "        'dtype': int,  # Tipo de dato: entero\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture\n",
    "def pipeline():\n",
    "    # Crear una instancia de la clase SimplePipeline\n",
    "    pl = SimplePipeline()\n",
    "    \n",
    "    # Ejecutar el pipeline, lo que incluye cargar el dataset, entrenar el modelo, etc.\n",
    "    pl.run_pipeline()\n",
    "    \n",
    "    # Devolver la instancia del pipeline\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                           [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.08s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_input_data_ranges(pipeline):\n",
    "    # Obtener los valores máximos y mínimos solo para las columnas numéricas\n",
    "    numeric_columns = pipeline.frame.select_dtypes(include=['float64', 'int64']).columns\n",
    "    max_values = pipeline.frame[numeric_columns].max()\n",
    "    min_values = pipeline.frame[numeric_columns].min()\n",
    "    \n",
    "    # Asegurarse de que los valores máximos y mínimos estén dentro del rango esperado\n",
    "    for feature in numeric_columns:\n",
    "        if 'range' in tumor_schema[feature]:\n",
    "            assert max_values[feature] <= tumor_schema[feature]['range']['max'], f\"{feature} excede el valor máximo permitido\"\n",
    "            assert min_values[feature] >= tumor_schema[feature]['range']['min'], f\"{feature} está por debajo del valor mínimo permitido\"\n",
    "    \n",
    "    # Para las columnas categóricas, comprobar los valores permitidos\n",
    "    categorical_columns = pipeline.frame.select_dtypes(include=['category']).columns\n",
    "    for feature in categorical_columns:\n",
    "        if 'allowed_values' in tumor_schema[feature]:\n",
    "            unique_values = pipeline.frame[feature].cat.categories\n",
    "            assert all(value in tumor_schema[feature]['allowed_values'] for value in unique_values), f\"{feature} contiene valores no permitidos\"\n",
    "\n",
    "def test_input_data_types(pipeline):\n",
    "    # Obtener los tipos de datos de cada columna\n",
    "    data_types = pipeline.frame.dtypes\n",
    "    \n",
    "    # Probar la compatibilidad entre los tipos de datos\n",
    "    for feature in pipeline.frame.columns:\n",
    "        expected_type = tumor_schema[feature]['dtype']\n",
    "        \n",
    "        # Comparar teniendo en cuenta que 'category' se usa para valores categóricos en lugar de int\n",
    "        if data_types[feature].name == 'category':\n",
    "            assert expected_type == int, f\"{feature} debe ser de tipo categórico pero se esperaba int en el esquema\"\n",
    "        else:\n",
    "            # Verificar compatibilidad de tipos\n",
    "            if expected_type == int:\n",
    "                assert pd.api.types.is_integer_dtype(data_types[feature]), f\"{feature} tiene un tipo incompatible\"\n",
    "            elif expected_type == float:\n",
    "                assert pd.api.types.is_float_dtype(data_types[feature]), f\"{feature} tiene un tipo incompatible\"\n",
    "            elif expected_type == str:\n",
    "                assert pd.api.types.is_string_dtype(data_types[feature]), f\"{feature} tiene un tipo incompatible\"\n",
    "            else:\n",
    "                assert data_types[feature] == expected_type, f\"{feature} tiene un tipo incompatible\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
