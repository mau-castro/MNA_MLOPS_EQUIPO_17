{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipytest\n",
      "  Downloading ipytest-0.14.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipytest) (8.14.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipytest) (23.1)\n",
      "Requirement already satisfied: pytest>=5.4 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipytest) (8.3.3)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytest>=5.4->ipytest) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytest>=5.4->ipytest) (1.2.2)\n",
      "Requirement already satisfied: tomli>=1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytest>=5.4->ipytest) (0.4.6)\n",
      "Requirement already satisfied: backcall in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->ipytest) (5.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython->ipytest) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->ipytest) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython->ipytest) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython->ipytest) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython->ipytest) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython->ipytest) (1.16.0)\n",
      "Installing collected packages: ipytest\n",
      "Successfully installed ipytest-0.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la biblioteca pandas para el manejo de datos\n",
    "import pandas as pd\n",
    "\n",
    "# Importa la biblioteca numpy para operaciones numéricas\n",
    "import numpy as np\n",
    "\n",
    "# Importa el módulo datasets de sklearn para cargar conjuntos de datos\n",
    "from sklearn import datasets\n",
    "\n",
    "# Importa la clase LogisticRegression de sklearn para la regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importa la función train_test_split de sklearn para dividir los datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importa la clase StandardScaler de sklearn para la normalización de datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importa la biblioteca pytest para pruebas unitarias\n",
    "import pytest\n",
    "\n",
    "# Importa la biblioteca ipytest para ejecutar pruebas en Jupyter Notebook\n",
    "import ipytest\n",
    "\n",
    "# Configura ipytest para que se ejecute automáticamente\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV y lo carga en un DataFrame de pandas\n",
    "dataset = pd.read_csv(r\"../../data/processed/TCGA_GBM_LGG_Mutations_clean_v2.csv\") # cambiar la ruta cuando se pruebe\n",
    "\n",
    "# Crea un DataFrame de pandas con las columnas del dataset\n",
    "dataset_df = pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "# Convierte la columna 'Grade' a tipo 'category'\n",
    "dataset_df[\"Grade\"] = dataset_df[\"Grade\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePipeline:\n",
    "    def __init__(self):\n",
    "        self.frame = None\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        self.model = None\n",
    "        self.load_dataset()\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        # Lee el archivo CSV y lo carga en un DataFrame de pandas\n",
    "        dataset = pd.read_csv(r\"../../data/processed/TCGA_GBM_LGG_Mutations_clean_v2.csv\")\n",
    "        \n",
    "        # Obtiene los nombres de las características excluyendo la columna 'Grade'\n",
    "        self.feature_names = dataset.columns.drop('Grade')\n",
    "        self.frame = dataset\n",
    "        \n",
    "        # Divide el dataset en conjuntos de entrenamiento y prueba\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.frame[self.feature_names], self.frame['Grade'], test_size=0.65, random_state=42)\n",
    "        \n",
    "    def train(self, algorithm=LogisticRegression):\n",
    "        # Entrena el modelo utilizando el algoritmo especificado (por defecto, regresión logística)\n",
    "        self.model = algorithm(solver='lbfgs', multi_class='auto')\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        # Realiza predicciones utilizando el modelo entrenado\n",
    "        return self.model.predict(input_data)\n",
    "        \n",
    "    def get_accuracy(self):\n",
    "        # Calcula y devuelve la precisión del modelo en el conjunto de prueba\n",
    "        return self.model.score(X=self.X_test, y=self.y_test)\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Método de ejecución para correr la pipeline varias veces.\"\"\"\n",
    "        self.load_dataset()\n",
    "        self.train()\n",
    "\n",
    "\n",
    "class PipelineWithFeatureEngineering(SimplePipeline):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(self.X_train)\n",
    "    \n",
    "    def apply_scaler(self):\n",
    "        # Aplica la normalización a los conjuntos de entrenamiento y prueba\n",
    "        self.X_train = self.scaler.transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        # Normaliza los datos de entrada antes de realizar predicciones\n",
    "        scaled_input_data = self.scaler.transform(input_data)\n",
    "        return self.model.predict(scaled_input_data)\n",
    "                  \n",
    "    def run_pipeline(self):\n",
    "        self.load_dataset()\n",
    "        self.apply_scaler()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo es: 0.9157706093189965\n"
     ]
    }
   ],
   "source": [
    "# Crea una instancia de la clase PipelineWithFeatureEngineering\n",
    "pipeline = PipelineWithFeatureEngineering()\n",
    "\n",
    "# Ejecuta la pipeline, que incluye la carga del dataset, la normalización y el entrenamiento del modelo\n",
    "pipeline.run_pipeline()\n",
    "\n",
    "# Obtiene la precisión del modelo en el conjunto de prueba\n",
    "accuracy_score = pipeline.get_accuracy()\n",
    "\n",
    "# Imprime la precisión del modelo\n",
    "print(f'La precisión del modelo es: {accuracy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture\n",
    "def pipeline():\n",
    "    # Crea una instancia de la clase PipelineWithFeatureEngineering\n",
    "    pl = PipelineWithFeatureEngineering()\n",
    "    \n",
    "    # Carga el conjunto de datos en la instancia de la pipeline\n",
    "    pl.load_dataset()\n",
    "    \n",
    "    # Devuelve la instancia de la pipeline\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                           [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_scaler_preprocessing_brings_x_train_mean_near_zero(pipeline):\n",
    "    # Calcula la media original de X_train\n",
    "    original_mean = pipeline.X_train.stack().mean()\n",
    "    \n",
    "    # Aplica la normalización a X_train\n",
    "    pipeline.apply_scaler()\n",
    "    \n",
    "    # Verifica que la media original es mayor que la media de X_train después de la normalización\n",
    "    assert original_mean > pipeline.X_train.mean()\n",
    "    \n",
    "    # Verifica que la media de X_train después de la normalización está cerca de 0\n",
    "    assert np.isclose(pipeline.X_train.mean(), 0.0, atol=1e-3)\n",
    "\n",
    "    # Imprime la media original y la media transformada de X_train\n",
    "    print(f'La media de X_train original es: {original_mean}')\n",
    "    print(f'La media de X_train transformada es: {pipeline.X_train.mean()}')\n",
    "\n",
    "def test_scaler_preprocessing_brings_x_train_std_near_one(pipeline):\n",
    "    # Aplica la normalización a X_train\n",
    "    pipeline.apply_scaler()\n",
    "    \n",
    "    # Verifica que la desviación estándar de X_train después de la normalización está cerca de 1\n",
    "    assert np.isclose(pipeline.X_train.std(), 1.0, atol=1e-3)\n",
    "    \n",
    "    # Imprime la desviación estándar de X_train transformada\n",
    "    print(f'La desviación estándar de X_train transformada es: {pipeline.X_train.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hacer que el test fallé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
      "============================================ FAILURES =============================================\n",
      "\u001b[31m\u001b[1m_____________________ test_scaler_preprocessing_brings_x_train_mean_near_zero _____________________\u001b[0m\n",
      "\n",
      "pipeline = <__main__.PipelineWithFeatureEngineering object at 0x0000019D65E84850>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_scaler_preprocessing_brings_x_train_mean_near_zero\u001b[39;49;00m(pipeline):\u001b[90m\u001b[39;49;00m\n",
      "        original_mean = pipeline.X_train.stack().mean()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        pipeline.apply_scaler()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Changing the assertion, so it will fail\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m original_mean < pipeline.X_train.mean()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 2.562661251791687 < -9.477297996481667e-18\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where -9.477297996481667e-18 = <built-in method mean of numpy.ndarray object at 0x0000019D65E2AC10>()\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <built-in method mean of numpy.ndarray object at 0x0000019D65E2AC10> = array([[-1.22988009, -0.97262153, -0.25356194, ..., -0.16580533,\\n        -0.13041013, -0.14310072],\\n       [ 0.8130873...013, -0.14310072],\\n       [ 0.81308739, -0.96500698, -0.25356194, ..., -0.16580533,\\n        -0.13041013, -0.14310072]]).mean\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +      where array([[-1.22988009, -0.97262153, -0.25356194, ..., -0.16580533,\\n        -0.13041013, -0.14310072],\\n       [ 0.8130873...013, -0.14310072],\\n       [ 0.81308739, -0.96500698, -0.25356194, ..., -0.16580533,\\n        -0.13041013, -0.14310072]]) = <__main__.PipelineWithFeatureEngineering object at 0x0000019D65E84850>.X_train\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_27652\\568615787.py\u001b[0m:7: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info =====================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_e8c822b967a8406b971a1cf137ea9be0.py::\u001b[1mtest_scaler_preprocessing_brings_x_train_mean_near_zero\u001b[0m - assert 2.562661251791687 < -9.477297996481667e-18\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.09s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_scaler_preprocessing_brings_x_train_mean_near_zero(pipeline):\n",
    "    # Calcula la media original de X_train\n",
    "    original_mean = pipeline.X_train.stack().mean()\n",
    "    \n",
    "    # Aplica la normalización a X_train\n",
    "    pipeline.apply_scaler()\n",
    "\n",
    "    # Cambia la aserción para que falle\n",
    "    assert original_mean < pipeline.X_train.mean()\n",
    "\n",
    "    # Cambia el valor en isclose para que falle\n",
    "    assert not np.isclose(pipeline.X_train.mean(), 1.0, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
      "============================================ FAILURES =============================================\n",
      "\u001b[31m\u001b[1m______________________ test_scaler_preprocessing_brings_x_train_std_near_one ______________________\u001b[0m\n",
      "\n",
      "pipeline = <__main__.PipelineWithFeatureEngineering object at 0x0000019D65F1F0A0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_scaler_preprocessing_brings_x_train_std_near_one\u001b[39;49;00m(pipeline):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Adding huge variation in the data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        pipeline.X_train *= \u001b[94m1000\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        pipeline.apply_scaler()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Testing with the original tolerance\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m np.isclose(pipeline.X_train.std(), \u001b[94m1.0\u001b[39;49;00m, atol=\u001b[94m1e-3\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = <function isclose at 0x0000019D369F6C20>(1270.4740150219047, 1.0, atol=0.001)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <function isclose at 0x0000019D369F6C20> = np.isclose\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    and   1270.4740150219047 = <built-in method std of numpy.ndarray object at 0x0000019D65EBAF70>()\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +      where <built-in method std of numpy.ndarray object at 0x0000019D65EBAF70> = array([[-1.22988009e+00,  2.22215590e+03,  2.22737015e+03, ...,\\n        -1.65805334e-01, -1.30410133e-01, -1.43100719e...  [ 2.04173761e+03,  2.22977046e+03,  2.22737015e+03, ...,\\n        -1.65805334e-01, -1.30410133e-01, -1.43100719e-01]]).std\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +        where array([[-1.22988009e+00,  2.22215590e+03,  2.22737015e+03, ...,\\n        -1.65805334e-01, -1.30410133e-01, -1.43100719e...  [ 2.04173761e+03,  2.22977046e+03,  2.22737015e+03, ...,\\n        -1.65805334e-01, -1.30410133e-01, -1.43100719e-01]]) = <__main__.PipelineWithFeatureEngineering object at 0x0000019D65F1F0A0>.X_train\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_27652\\3289142395.py\u001b[0m:8: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info =====================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_e8c822b967a8406b971a1cf137ea9be0.py::\u001b[1mtest_scaler_preprocessing_brings_x_train_std_near_one\u001b[0m - assert False\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.06s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_scaler_preprocessing_brings_x_train_std_near_one(pipeline):\n",
    "    # Añade una gran variación en los datos\n",
    "    pipeline.X_train *= 1000\n",
    "\n",
    "    # Aplica la normalización a X_train\n",
    "    pipeline.apply_scaler()\n",
    "\n",
    "    # Prueba con la tolerancia original\n",
    "    assert np.isclose(pipeline.X_train.std(), 1.0, atol=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
